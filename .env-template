# LLAMA Model size
MODEL_SIZE=7B

# LLAMA model path
INPUT_DIR=/app/models/llama/$MODEL_SIZE

# Model name
MODEL_TYPE=Chinese-Alpaca-Plus

# LoRA name
LORA_NAME_1=chinese-llama-plus-lora-7b
LORA_NAME_2=chinese-alpaca-plus-lora-7b

# Model path after conversion to HF format
HF_OUTPUT_DIR=$INPUT_DIR/$MODEL_SIZE-HF

# LoRA path and LoRA name
LORA_PATH=$INPUT_DIR/LoRA
LORA_MODEL=$LORA_PATH/$LORA_NAME_1,$LORA_PATH/$LORA_NAME_2

# Model format
OUTPUT_TYPE=pth

# Model position after conversion and merging
MERGED_OUTPUT_DIR=$INPUT_DIR/$MODEL_TYPE/$MODEL_SIZE

# 
QUANTIZE_TYPE=q4_0

## llama.cpp 启动参数
#CLI_ARGS=--color -f prompts/alpaca.txt -ins -c 2048 --temp 0.2 -n 256 --repeat_penalty 1.1
